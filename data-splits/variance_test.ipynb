{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ignore metric did not predict warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean, mode\n",
    "from pathlib import Path\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV, cross_val_score, cross_validate, validation_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACD</th>\n",
       "      <th>LT</th>\n",
       "      <th>VCD</th>\n",
       "      <th>SPORTHR</th>\n",
       "      <th>DADMY</th>\n",
       "      <th>delta_spheq</th>\n",
       "      <th>total_positive_screen</th>\n",
       "      <th>MYOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.702</td>\n",
       "      <td>3.392</td>\n",
       "      <td>15.29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.358</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACD     LT    VCD  SPORTHR  DADMY  delta_spheq  total_positive_screen  \\\n",
       "0  3.702  3.392  15.29        4      1        1.358                      8   \n",
       "\n",
       "   MYOPIC  \n",
       "0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"../eda/reduced_filtered_df.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X,y\n",
    "label = df[\"MYOPIC\"]\n",
    "X = df.iloc[:,:-1].copy()\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training X Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 5,\n",
    " 'max_leaves': 4,\n",
    " 'min_child_weight': 3.5806456485030385,\n",
    " 'learning_rate': 0.4359086627863047,\n",
    " 'subsample': 1.0,\n",
    " 'colsample_bylevel': 0.9122163035553499,\n",
    " 'colsample_bytree': 0.9599028390069959,\n",
    " 'reg_alpha': 0.11831815110092216,\n",
    " 'reg_lambda': 0.07223617575057466\n",
    " }\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scoring = ('f1', 'recall', 'precision', 'roc_auc', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  334\n",
      "Test Accuracy\n",
      "0.8715092097445039\n",
      "0.0376546676660325\n",
      "ROC_AUC\n",
      "0.8442528735632185\n",
      "0.09608140100441981\n",
      "Precision\n",
      "0.5484920634920634\n",
      "0.31800022541037315\n"
     ]
    }
   ],
   "source": [
    "# Holdback Method with stratify as True\n",
    "X_train90, X_test10, y_train90, y_test10 = train_test_split(X, label, random_state=42, stratify=label, train_size=0.9)\n",
    "print(\"Rows: \",len(X_train90))\n",
    "\n",
    "scores = cross_validate(model, X_train90, y_train90, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  296\n",
      "Test Accuracy\n",
      "0.8808045977011496\n",
      "0.0500320503258196\n",
      "ROC_AUC\n",
      "0.8392008547008547\n",
      "0.1038687346628929\n",
      "Precision\n",
      "0.586111111111111\n",
      "0.35386970120667127\n"
     ]
    }
   ],
   "source": [
    "X_train80, X_test11, y_train80, y_test11 = train_test_split(X_train90, y_train90, random_state=42, stratify=y_train90, train_size=0.889)\n",
    "print(\"Rows: \",len(X_train80))\n",
    "scores = cross_validate(model, X_train80, y_train80, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  259\n",
      "Accuracy\n",
      "0.8752820512820512\n",
      "0.04912477906794787\n",
      "ROC_AUC\n",
      "0.8480978260869564\n",
      "0.1198015771374923\n",
      "Precision\n",
      "0.5277777777777778\n",
      "0.4024078761225134\n"
     ]
    }
   ],
   "source": [
    "X_train70, X_test12, y_train70, y_test12 = train_test_split(X_train80, y_train80, random_state=42, stratify=y_train80, train_size=0.875)\n",
    "print(\"Rows: \",len(X_train70))\n",
    "scores = cross_validate(model, X_train70, y_train70, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print('Accuracy')\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  221\n",
      "Test Accuracy\n",
      "0.8731884057971013\n",
      "0.043165974346751776\n",
      "ROC_AUC\n",
      "0.8635891812865496\n",
      "0.08147944560964503\n",
      "Precision\n",
      "0.4527777777777778\n",
      "0.3724812531532524\n"
     ]
    }
   ],
   "source": [
    "X_train60, X_test14, y_train60, y_test14 = train_test_split(X_train70, y_train70, random_state=42, stratify=y_train70, train_size=0.857)\n",
    "print(\"Rows: \",len(X_train60))\n",
    "scores = cross_validate(model, X_train60, y_train60, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  184\n",
      "Test Accuracy\n",
      "0.8897660818713449\n",
      "0.044799227737004496\n",
      "ROC_AUC\n",
      "0.8527777777777777\n",
      "0.12588613375920124\n",
      "Precision\n",
      "0.6472222222222221\n",
      "0.3533459990741772\n"
     ]
    }
   ],
   "source": [
    "X_train50, X_test16, y_train50, y_test16 = train_test_split(X_train60, y_train60, random_state=42, stratify=y_train60, train_size=0.833)\n",
    "print(\"Rows: \",len(X_train50))\n",
    "scores = cross_validate(model, X_train50, y_train50, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  186\n",
      "Test Accuracy\n",
      "0.8731968810916179\n",
      "0.04346464973725452\n",
      "ROC_AUC\n",
      "0.7796670751633988\n",
      "0.1442073617012899\n",
      "Precision\n",
      "0.2111111111111111\n",
      "0.3989182904670275\n"
     ]
    }
   ],
   "source": [
    "# Holdback Method with stratify as True\n",
    "X_train51, X_test50, y_train51, y_test50 = train_test_split(X, label, random_state=42, stratify=label, train_size=0.5)\n",
    "print(\"Rows: \",len(X_test50))\n",
    "scores = cross_validate(model, X_test50, y_test50, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  149\n",
      "Test Accuracy\n",
      "0.863968253968254\n",
      "0.031121232561551346\n",
      "ROC_AUC\n",
      "0.760897435897436\n",
      "0.14626204946513283\n",
      "Precision\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train20, X_test40, y_train20, y_test40 = train_test_split(X_test50, y_test50, random_state=42, stratify=y_test50, test_size=0.8)\n",
    "print(\"Rows: \",len(X_test40))\n",
    "scores = cross_validate(model, X_test40, y_test40, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  112\n",
      "Test Accuracy\n",
      "0.8757575757575757\n",
      "0.04110503020075917\n",
      "ROC_AUC\n",
      "0.7974074074074075\n",
      "0.16373962652615448\n",
      "Precision\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train25, X_test30, y_train25, y_test30 = train_test_split(X_test40, y_test40, random_state=42, stratify=y_test40, test_size=0.75)\n",
    "print(\"Rows: \",len(X_test30))\n",
    "scores = cross_validate(model, X_test30, y_test30, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  75\n",
      "Test Accuracy\n",
      "nan\n",
      "nan\n",
      "ROC_AUC\n",
      "nan\n",
      "nan\n",
      "Precision\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "X_train33, X_test20, y_train33, y_test20 = train_test_split(X_test30, y_test30, random_state=42, stratify=y_test30, test_size=0.666)\n",
    "print(\"Rows: \",len(X_test20))\n",
    "scores = cross_validate(model, X_test20, y_test20, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  38\n",
      "Test Accuracy\n",
      "nan\n",
      "nan\n",
      "ROC_AUC\n",
      "nan\n",
      "nan\n",
      "Precision\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "X_train49, X_test10, y_train49, y_test10 = train_test_split(X_test20, y_test20, random_state=42, stratify=y_test20, test_size=0.5)\n",
    "print(\"Rows: \",len(X_test10))\n",
    "scores = cross_validate(model, X_test10, y_test10, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('PythonDataS2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b60c06e5cbd3604200bba38e15999842eea86127b4e1a9a5738b9a4fd10c0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
