{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ignore metric did not predict warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean, mode\n",
    "from pathlib import Path\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV, cross_val_score, cross_validate, validation_curve\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACD</th>\n",
       "      <th>LT</th>\n",
       "      <th>VCD</th>\n",
       "      <th>SPORTHR</th>\n",
       "      <th>DADMY</th>\n",
       "      <th>delta_spheq</th>\n",
       "      <th>total_positive_screen</th>\n",
       "      <th>MYOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.702</td>\n",
       "      <td>3.392</td>\n",
       "      <td>15.29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.358</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACD     LT    VCD  SPORTHR  DADMY  delta_spheq  total_positive_screen  \\\n",
       "0  3.702  3.392  15.29        4      1        1.358                      8   \n",
       "\n",
       "   MYOPIC  \n",
       "0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"../eda/reduced_filtered_df.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X,y\n",
    "label = df[\"MYOPIC\"]\n",
    "X = df.iloc[:,:-1].copy()\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646\n"
     ]
    }
   ],
   "source": [
    "over = SMOTE()\n",
    "X, label = over.fit_resample(X, label)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training X Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 5,\n",
    " 'max_leaves': 4,\n",
    " 'min_child_weight': 3.5806456485030385,\n",
    " 'learning_rate': 0.4359086627863047,\n",
    " 'subsample': 1.0,\n",
    " 'colsample_bylevel': 0.9122163035553499,\n",
    " 'colsample_bytree': 0.9599028390069959,\n",
    " 'reg_alpha': 0.11831815110092216,\n",
    " 'reg_lambda': 0.07223617575057466\n",
    " }\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scoring = ('neg_log_loss','f1', 'recall', 'precision', 'roc_auc', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "train=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  581\n",
      "LogLoss\n",
      "-0.3304520654389886\n",
      "0.057799834358106116\n",
      "Test Accuracy\n",
      "0.8560198714202222\n",
      "0.043331501693318585\n",
      "ROC_AUC\n",
      "0.936114414057339\n",
      "0.028574151556665553\n",
      "Precision\n",
      "0.8427464283537208\n",
      "0.05167557670132483\n"
     ]
    }
   ],
   "source": [
    "# Holdback Method with stratify as True\n",
    "X_train90, X_test10, y_train90, y_test10 = train_test_split(X, label, random_state=42, stratify=label, train_size=0.9)\n",
    "print(\"Rows: \",len(X_train90))\n",
    "\n",
    "scores = cross_validate(model, X_train90, y_train90, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  516\n",
      "LogLoss\n",
      "-0.3432068450948593\n",
      "0.06609259221800938\n",
      "Test Accuracy\n",
      "0.8520739064856714\n",
      "0.048675275732130624\n",
      "ROC_AUC\n",
      "0.9305946745562129\n",
      "0.03668723542801351\n",
      "Precision\n",
      "0.8416909226204439\n",
      "0.06447378523480135\n"
     ]
    }
   ],
   "source": [
    "X_train80, X_test11, y_train80, y_test11 = train_test_split(X_train90, y_train90, random_state=42, stratify=y_train90, train_size=0.889)\n",
    "print(\"Rows: \",len(X_train80))\n",
    "scores = cross_validate(model, X_train80, y_train80, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  451\n",
      "LogLoss\n",
      "-0.34101917987121155\n",
      "0.05925686902420103\n",
      "Accuracy\n",
      "0.8521256038647343\n",
      "0.05186530516303661\n",
      "ROC_AUC\n",
      "0.9292189379618492\n",
      "0.03078303238547664\n",
      "Precision\n",
      "0.8409622157513081\n",
      "0.06040127528671199\n"
     ]
    }
   ],
   "source": [
    "X_train70, X_test12, y_train70, y_test12 = train_test_split(X_train80, y_train80, random_state=42, stratify=y_train80, train_size=0.875)\n",
    "print(\"Rows: \",len(X_train70))\n",
    "scores = cross_validate(model, X_train70, y_train70, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print('Accuracy')\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  386\n",
      "LogLoss\n",
      "-0.3632005847450262\n",
      "0.07317653649939453\n",
      "Test Accuracy\n",
      "0.8515069725596042\n",
      "0.05182195997016847\n",
      "ROC_AUC\n",
      "0.9205794090489382\n",
      "0.03901928643360766\n",
      "Precision\n",
      "0.8433554510517425\n",
      "0.058476331145701596\n"
     ]
    }
   ],
   "source": [
    "X_train60, X_test14, y_train60, y_test14 = train_test_split(X_train70, y_train70, random_state=42, stratify=y_train70, train_size=0.857)\n",
    "print(\"Rows: \",len(X_train60))\n",
    "scores = cross_validate(model, X_train60, y_train60, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  321\n",
      "LogLoss\n",
      "-0.3786034552737894\n",
      "0.0878271289570954\n",
      "Test Accuracy\n",
      "0.8309343434343435\n",
      "0.0716895186497029\n",
      "ROC_AUC\n",
      "0.9130438112745097\n",
      "0.05148526136610341\n",
      "Precision\n",
      "0.8267325626729654\n",
      "0.08664441467316882\n"
     ]
    }
   ],
   "source": [
    "X_train50, X_test16, y_train50, y_test16 = train_test_split(X_train60, y_train60, random_state=42, stratify=y_train60, train_size=0.833)\n",
    "print(\"Rows: \",len(X_train50))\n",
    "scores = cross_validate(model, X_train50, y_train50, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  323\n",
      "LogLoss\n",
      "-0.40328512848615133\n",
      "0.09600388720272941\n",
      "Test Accuracy\n",
      "0.8317550505050505\n",
      "0.07002298609036994\n",
      "ROC_AUC\n",
      "0.8942593443627451\n",
      "0.05666302742851915\n",
      "Precision\n",
      "0.8021167375272907\n",
      "0.08716170916020664\n"
     ]
    }
   ],
   "source": [
    "# Holdback Method with stratify as True\n",
    "X_train51, X_test50, y_train51, y_test50 = train_test_split(X, label, random_state=42, stratify=label, train_size=0.5)\n",
    "print(\"Rows: \",len(X_test50))\n",
    "scores = cross_validate(model, X_test50, y_test50, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  259\n",
      "LogLoss\n",
      "-0.3915613257391312\n",
      "0.0968449230991469\n",
      "Test Accuracy\n",
      "0.8276923076923077\n",
      "0.06313068378145452\n",
      "ROC_AUC\n",
      "0.9045940170940173\n",
      "0.06486781140030325\n",
      "Precision\n",
      "0.8035571388822164\n",
      "0.08047118309736957\n"
     ]
    }
   ],
   "source": [
    "X_train20, X_test40, y_train20, y_test40 = train_test_split(X_test50, y_test50, random_state=42, stratify=y_test50, test_size=0.8)\n",
    "print(\"Rows: \",len(X_test40))\n",
    "scores = cross_validate(model, X_test40, y_test40, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  195\n",
      "LogLoss\n",
      "-0.41219052491022345\n",
      "0.1287424388842064\n",
      "Test Accuracy\n",
      "0.8230701754385967\n",
      "0.08872411339617785\n",
      "ROC_AUC\n",
      "0.8966666666666668\n",
      "0.0806677379788059\n",
      "Precision\n",
      "0.8132385207385207\n",
      "0.11320617542878846\n"
     ]
    }
   ],
   "source": [
    "X_train25, X_test30, y_train25, y_test30 = train_test_split(X_test40, y_test40, random_state=42, stratify=y_test40, test_size=0.75)\n",
    "print(\"Rows: \",len(X_test30))\n",
    "scores = cross_validate(model, X_test30, y_test30, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  130\n",
      "LogLoss\n",
      "-0.4051009163379504\n",
      "0.1484896381130932\n",
      "Test Accuracy\n",
      "0.8410256410256411\n",
      "0.09917476720930112\n",
      "ROC_AUC\n",
      "0.894047619047619\n",
      "0.1036170306468028\n",
      "Precision\n",
      "0.8199206349206349\n",
      "0.11974699329681776\n"
     ]
    }
   ],
   "source": [
    "X_train33, X_test20, y_train33, y_test20 = train_test_split(X_test30, y_test30, random_state=42, stratify=y_test30, test_size=0.666)\n",
    "print(\"Rows: \",len(X_test20))\n",
    "scores = cross_validate(model, X_test20, y_test20, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  65\n",
      "LogLoss\n",
      "-0.5113948004986508\n",
      "0.1974990200727832\n",
      "Test Accuracy\n",
      "0.7238095238095238\n",
      "0.16730038251426085\n",
      "ROC_AUC\n",
      "0.8314814814814816\n",
      "0.1730540445408936\n",
      "Precision\n",
      "0.7144444444444444\n",
      "0.2337984781709704\n"
     ]
    }
   ],
   "source": [
    "X_train49, X_test10, y_train49, y_test10 = train_test_split(X_test20, y_test20, random_state=42, stratify=y_test20, test_size=0.5)\n",
    "print(\"Rows: \",len(X_test10))\n",
    "scores = cross_validate(model, X_test10, y_test10, scoring=scoring, cv=cv, n_jobs=1)\n",
    "print(\"LogLoss\")\n",
    "print(np.mean(scores['test_neg_log_loss']))\n",
    "print(np.std(scores['test_neg_log_loss']))\n",
    "print(\"Test Accuracy\")\n",
    "print(np.mean(scores['test_accuracy']))\n",
    "print(np.std(scores['test_accuracy']))\n",
    "print(\"ROC_AUC\")\n",
    "print(np.mean(scores['test_roc_auc']))\n",
    "print(np.std(scores['test_roc_auc']))\n",
    "print(\"Precision\")\n",
    "print(np.mean(scores['test_precision']))\n",
    "print(np.std(scores['test_precision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a minimum of 150 samples (Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('PythonDataS2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b60c06e5cbd3604200bba38e15999842eea86127b4e1a9a5738b9a4fd10c0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
